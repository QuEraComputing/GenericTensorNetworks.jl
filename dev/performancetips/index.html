<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Performance Tips · GenericTensorNetworks.jl</title><script data-outdated-warner src="../assets/warner.js"></script><link rel="canonical" href="https://QuEraComputing.github.io/GenericTensorNetworks.jl/performancetips/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.044/juliamono.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.11/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="../assets/indigo.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">GenericTensorNetworks.jl</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><span class="tocitem">Problems</span><ul><li><a class="tocitem" href="../generated/IndependentSet/">Independent set problem</a></li><li><a class="tocitem" href="../generated/MaximalIS/">Maximal independent set problem</a></li><li><a class="tocitem" href="../generated/SpinGlass/">Spin glass problem</a></li><li><a class="tocitem" href="../generated/MaxCut/">Cutting problem</a></li><li><a class="tocitem" href="../generated/Matching/">Vertex matching problem</a></li><li><a class="tocitem" href="../generated/PaintShop/">Binary paint shop problem</a></li><li><a class="tocitem" href="../generated/Coloring/">Coloring problem</a></li><li><a class="tocitem" href="../generated/DominatingSet/">Dominating set problem</a></li><li><a class="tocitem" href="../generated/Satisfiability/">Satisfiability problem</a></li><li><a class="tocitem" href="../generated/SetCovering/">Set covering problem</a></li><li><a class="tocitem" href="../generated/SetPacking/">Set packing problem</a></li></ul></li><li><span class="tocitem">Topics</span><ul><li><a class="tocitem" href="../gist/">Gist</a></li><li><a class="tocitem" href="../generated/saveload/">Save and load solutions</a></li><li><a class="tocitem" href="../sumproduct/">Sum product tree representation</a></li><li><a class="tocitem" href="../generated/weighted/">Weighted problems</a></li><li><a class="tocitem" href="../generated/open/">Open and fixed degrees of freedom</a></li></ul></li><li class="is-active"><a class="tocitem" href>Performance Tips</a><ul class="internal"><li><a class="tocitem" href="#Optimize-contraction-orders"><span>Optimize contraction orders</span></a></li><li><a class="tocitem" href="#Slicing-technique"><span>Slicing technique</span></a></li><li><a class="tocitem" href="#GEMM-for-Tropical-numbers"><span>GEMM for Tropical numbers</span></a></li><li><a class="tocitem" href="#Multiprocessing"><span>Multiprocessing</span></a></li><li><a class="tocitem" href="#Make-use-of-GPUs"><span>Make use of GPUs</span></a></li><li><a class="tocitem" href="#Benchmarks"><span>Benchmarks</span></a></li></ul></li><li><a class="tocitem" href="../ref/">References</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Performance Tips</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Performance Tips</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/QuEraComputing/GenericTensorNetworks.jl/blob/master/docs/src/performancetips.md#" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Performance-Tips"><a class="docs-heading-anchor" href="#Performance-Tips">Performance Tips</a><a id="Performance-Tips-1"></a><a class="docs-heading-anchor-permalink" href="#Performance-Tips" title="Permalink"></a></h1><h2 id="Optimize-contraction-orders"><a class="docs-heading-anchor" href="#Optimize-contraction-orders">Optimize contraction orders</a><a id="Optimize-contraction-orders-1"></a><a class="docs-heading-anchor-permalink" href="#Optimize-contraction-orders" title="Permalink"></a></h2><p>Let us use the independent set problem on 3-regular graphs as an example.</p><pre><code class="language-julia hljs">julia&gt; using GenericTensorNetworks, Graphs, Random

julia&gt; graph = random_regular_graph(120, 3)
{120, 180} undirected simple Int64 graph

julia&gt; problem = IndependentSet(graph; optimizer=TreeSA(
    sc_target=20, sc_weight=1.0, rw_weight=3.0, ntrials=10, βs=0.01:0.1:15.0, niters=20), simplifier=MergeGreedy());</code></pre><p>The <a href="../ref/#GenericTensorNetworks.IndependentSet"><code>IndependentSet</code></a> constructor maps an independent set problem to a tensor network with optimized contraction order. The key word argument <code>optimizer</code> specifies the contraction order optimizer of the tensor network. Here, we choose the local search based <a href="../ref/#OMEinsumContractionOrders.TreeSA"><code>TreeSA</code></a> algorithm, which often finds the smallest time/space complexity and supports slicing. One can type <code>?TreeSA</code> in a Julia REPL for more information about how to configure the hyper-parameters of the <a href="../ref/#OMEinsumContractionOrders.TreeSA"><code>TreeSA</code></a> method,  while the detailed algorithm explanation is in <a href="https://arxiv.org/abs/2108.05665">arXiv: 2108.05665</a>. Alternative tensor network contraction order optimizers include</p><ul><li><a href="../ref/#OMEinsumContractionOrders.GreedyMethod"><code>GreedyMethod</code></a> (default, fastest in searching speed but worst in contraction complexity)</li><li><a href="../ref/#OMEinsumContractionOrders.KaHyParBipartite"><code>KaHyParBipartite</code></a></li><li><a href="../ref/#OMEinsumContractionOrders.SABipartite"><code>SABipartite</code></a></li></ul><p>The keyword argument <code>simplifier</code> specifies the preprocessor to improve the searching speed of the contraction order finding. For example, the <code>MergeGreedy()</code> here &quot;contracts&quot; tensors greedily whenever the contraction result has a smaller space complexity. It can remove all vertex tensors (vectors) before entering the contraction order optimization algorithm.</p><p>The returned object <code>problem</code> contains a field <code>code</code> that specifies the tensor network with optimized contraction order. For an independent set problem, the optimal contraction time/space complexity is <span>$\sim 2^{{\rm tw}(G)}$</span>, where <span>${\rm tw(G)}$</span> is the <a href="https://en.wikipedia.org/wiki/Treewidth">tree-width</a> of <span>$G$</span>. One can check the time, space and read-write complexity with the <a href="../ref/#OMEinsum.timespacereadwrite_complexity"><code>timespacereadwrite_complexity</code></a> function.</p><pre><code class="language-julia hljs">julia&gt; timespacereadwrite_complexity(problem)
(21.90683335864693, 17.0, 20.03588509836998)</code></pre><p>The return values are <code>log2</code> values of the number of multiplications, the number elements in the largest tensor during contraction and the number of read-write operations to tensor elements. In this example, the number <code>*</code> operations is <span>$\sim 2^{21.9}$</span>, the number of read-write operations are <span>$\sim 2^{20}$</span>, and the largest tensor size is <span>$2^{17}$</span>. One can check the element size by typing</p><pre><code class="language-julia hljs">julia&gt; sizeof(TropicalF64)
8

julia&gt; sizeof(TropicalF32)
4

julia&gt; sizeof(StaticBitVector{200,4})
32

julia&gt; sizeof(TruncatedPoly{5,Float64,Float64})
48</code></pre><p>One can use <a href="../ref/#GenericTensorNetworks.estimate_memory"><code>estimate_memory</code></a> to get a good estimation of peak memory in bytes. For example, to compute the graph polynomial, the peak memory can be estimated as follows.</p><pre><code class="language-julia hljs">julia&gt; estimate_memory(problem, GraphPolynomial(; method=:finitefield))
297616

julia&gt; estimate_memory(problem, GraphPolynomial(; method=:polynomial))
71427840</code></pre><p>The finite field approach only requires 298 KB memory, while using the <a href="https://juliamath.github.io/Polynomials.jl/stable/polynomials/polynomial/#Polynomial-2"><code>Polynomial</code></a> number type requires 71 MB memory.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><ul><li>The actual run time memory can be several times larger than the size of the maximum tensor, so the <a href="../ref/#GenericTensorNetworks.estimate_memory"><code>estimate_memory</code></a> is more accurate in estimating the peak memory.</li><li>For mutable element types like <a href="../ref/#GenericTensorNetworks.ConfigEnumerator"><code>ConfigEnumerator</code></a>, none of memory estimation functions measure the actual memory usage correctly.</li></ul></div></div><h2 id="Slicing-technique"><a class="docs-heading-anchor" href="#Slicing-technique">Slicing technique</a><a id="Slicing-technique-1"></a><a class="docs-heading-anchor-permalink" href="#Slicing-technique" title="Permalink"></a></h2><p>For large scale applications, it is also possible to slice over certain degrees of freedom to reduce the space complexity, i.e. loop and accumulate over certain degrees of freedom so that one can have a smaller tensor network inside the loop due to the removal of these degrees of freedom. In the <a href="../ref/#OMEinsumContractionOrders.TreeSA"><code>TreeSA</code></a> optimizer, one can set <code>nslices</code> to a value larger than zero to turn on this feature.</p><pre><code class="language-julia hljs">julia&gt; using GenericTensorNetworks, Graphs, Random

julia&gt; graph = random_regular_graph(120, 3)
{120, 180} undirected simple Int64 graph

julia&gt; problem = IndependentSet(graph; optimizer=TreeSA(βs=0.01:0.1:25.0, ntrials=10, niters=10));

julia&gt; timespacereadwrite_complexity(problem)
(20.856518235241687, 16.0, 18.88208476145812)

julia&gt; problem = IndependentSet(graph; optimizer=TreeSA(βs=0.01:0.1:25.0, ntrials=10, niters=10, nslices=5));

julia&gt; timespacereadwrite_complexity(problem)
(21.134967710592804, 11.0, 19.84529401927876)</code></pre><p>In the second <code>IndependentSet</code> constructor, we slice over 5 degrees of freedom, which can reduce the space complexity by at most 5. In this application, the slicing achieves the largest possible space complexity reduction 5, while the time and read-write complexity are only increased by less than 1, i.e. the peak memory usage is reduced by a factor <span>$32$</span>, while the (theoretical) computing time is increased by at a factor <span>$&lt; 2$</span>.</p><h2 id="GEMM-for-Tropical-numbers"><a class="docs-heading-anchor" href="#GEMM-for-Tropical-numbers">GEMM for Tropical numbers</a><a id="GEMM-for-Tropical-numbers-1"></a><a class="docs-heading-anchor-permalink" href="#GEMM-for-Tropical-numbers" title="Permalink"></a></h2><p>One can speed up the Tropical number matrix multiplication when computing the solution space property <a href="../ref/#GenericTensorNetworks.SizeMax"><code>SizeMax</code></a><code>()</code> by using the Tropical GEMM routines implemented in package <a href="https://github.com/TensorBFS/TropicalGEMM.jl/"><code>TropicalGEMM</code></a>.</p><pre><code class="language-julia hljs">julia&gt; using BenchmarkTools

julia&gt; @btime solve(problem, SizeMax())
  91.630 ms (19203 allocations: 23.72 MiB)
0-dimensional Array{TropicalF64, 0}:
53.0ₜ

julia&gt; using TropicalGEMM

julia&gt; @btime solve(problem, SizeMax())
  8.960 ms (18532 allocations: 17.01 MiB)
0-dimensional Array{TropicalF64, 0}:
53.0ₜ</code></pre><p>The <code>TropicalGEMM</code> package pirates the <code>LinearAlgebra.mul!</code> interface, hence it takes effect upon using. The above example shows more than 10x speed up on a single thread CPU, which can be even faster if <a href="https://docs.julialang.org/en/v1/manual/multi-threading/">the Julia multi-threading</a> if turned on. The benchmark in the <code>TropicalGEMM</code> repo shows this performance is close to the theoretical optimal value.</p><h2 id="Multiprocessing"><a class="docs-heading-anchor" href="#Multiprocessing">Multiprocessing</a><a id="Multiprocessing-1"></a><a class="docs-heading-anchor-permalink" href="#Multiprocessing" title="Permalink"></a></h2><p>Submodule <code>GenericTensorNetworks.SimpleMutiprocessing</code> provides one function <a href="../ref/#GenericTensorNetworks.SimpleMultiprocessing.multiprocess_run"><code>GenericTensorNetworks.SimpleMultiprocessing.multiprocess_run</code></a> function for simple multi-processing jobs. It is not directly related to <code>GenericTensorNetworks</code>, but is very convenient to have one. Suppose we want to find the independence polynomial for multiple graphs with 4 processes. We can create a file, e.g. named <code>run.jl</code> with the following content</p><pre><code class="language-julia hljs">using Distributed, GenericTensorNetworks.SimpleMultiprocessing
using Random, GenericTensorNetworks  # to avoid multi-precompilation
@everywhere using Random, GenericTensorNetworks

results = multiprocess_run(collect(1:10)) do seed
    Random.seed!(seed)
    n = 10
    @info &quot;Graph size $n x $n, seed= $seed&quot;
    g = random_diagonal_coupled_graph(n, n, 0.8)
    gp = Independence(g; optimizer=TreeSA(), simplifier=MergeGreedy())
    res = solve(gp, GraphPolynomial())[]
    return res
end

println(results)</code></pre><p>One can run this script file with the following command</p><pre><code class="language-bash hljs">$ julia -p4 run.jl
      From worker 3:	[ Info: running argument 4 on device 3
      From worker 4:	[ Info: running argument 2 on device 4
      From worker 5:	[ Info: running argument 3 on device 5
      From worker 2:	[ Info: running argument 1 on device 2
      From worker 3:	[ Info: Graph size 10 x 10, seed= 4
      From worker 4:	[ Info: Graph size 10 x 10, seed= 2
      From worker 5:	[ Info: Graph size 10 x 10, seed= 3
      From worker 2:	[ Info: Graph size 10 x 10, seed= 1
      From worker 4:	[ Info: running argument 5 on device
      ...</code></pre><p>You will see a vector of polynomials printed out.</p><h2 id="Make-use-of-GPUs"><a class="docs-heading-anchor" href="#Make-use-of-GPUs">Make use of GPUs</a><a id="Make-use-of-GPUs-1"></a><a class="docs-heading-anchor-permalink" href="#Make-use-of-GPUs" title="Permalink"></a></h2><p>To upload the computation to GPU, you just add <code>using CUDA</code> before calling the <code>solve</code> function, and set the keyword argument <code>usecuda</code> to <code>true</code>.</p><pre><code class="language-julia hljs">julia&gt; using CUDA
[ Info: OMEinsum loaded the CUDA module successfully

julia&gt; solve(problem, SizeMax(), usecuda=true)
0-dimensional CuArray{TropicalF64, 0, CUDA.Mem.DeviceBuffer}:
53.0ₜ</code></pre><p>Solution space properties computable on GPU includes</p><ul><li><a href="../ref/#GenericTensorNetworks.SizeMax"><code>SizeMax</code></a> and <a href="../ref/#GenericTensorNetworks.SizeMin"><code>SizeMin</code></a></li><li><a href="../ref/#GenericTensorNetworks.CountingAll"><code>CountingAll</code></a></li><li><a href="../ref/#GenericTensorNetworks.CountingMax"><code>CountingMax</code></a> and <a href="../ref/#GenericTensorNetworks.CountingMin"><code>CountingMin</code></a></li><li><a href="../ref/#GenericTensorNetworks.GraphPolynomial"><code>GraphPolynomial</code></a></li><li><a href="../ref/#GenericTensorNetworks.SingleConfigMax"><code>SingleConfigMax</code></a> and <a href="../ref/#GenericTensorNetworks.SingleConfigMin"><code>SingleConfigMin</code></a></li></ul><h2 id="Benchmarks"><a class="docs-heading-anchor" href="#Benchmarks">Benchmarks</a><a id="Benchmarks-1"></a><a class="docs-heading-anchor-permalink" href="#Benchmarks" title="Permalink"></a></h2><p>We run a single thread benchmark on central processing units (CPU) Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz, and its CUDA version on a GPU Tesla V100-SXM2 16G. The results are summarized in the following plot. The benchmark code can be found in <a href="https://github.com/GiggleLiu/NoteOnTropicalMIS/tree/master/benchmarks">our paper repository</a>.</p><p><img src="../assets/fig1.png" alt="benchmark-independent-set"/> This benchmark results is for computing different solution space properties of independent sets of random three-regular graphs with different tensor element types. The time in these plots only includes tensor network contraction, without taking into account the contraction order finding and just-in-time compilation time. Legends are properties, algebra, and devices that we used in the computation; one can find the corresponding computed solution space property in Table 1 in the <a href="https://arxiv.org/abs/2205.03718">paper</a>.</p><ul><li>(a) time and space complexity versus the number of vertices for the benchmarked graphs.</li><li>(b) The computation time for calculating the MIS size and for counting the number of all independent sets (ISs), the number of MISs, the number of independent sets having size <span>$\alpha(G)$</span> and <span>$\alpha(G)-1$</span>, and finding 100 largest set sizes.</li><li>(c) The computation time for calculating the independence polynomials with different approaches.</li><li>(d) The computation time for configuration enumeration, including single MIS configuration, the enumeration of all independent set configurations, all MIS configurations, all independent sets, and all independent set configurations having size <span>$\alpha(G)$</span> and <span>$\alpha(G)-1$</span>.</li></ul><p>The graphs in all benchmarks are random three-regular graphs, which have treewidth that is asymptotically smaller than <span>$|V|/6$</span>. In this benchmark, we do not include traditional algorithms for finding the MIS sizes such as branching or dynamic programming. To the best of our knowledge, these algorithms are not suitable for computing most of the solution space properties mentioned in this paper. The main goal of this section is to show the relative computation time for calculating different solution space properties.</p><p>Panel (a) shows the time and space complexity of tensor network contraction for different graph sizes. The contraction order is obtained using the <code>TreeSA</code> algorithm that implemented in <a href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl">OMEinsumContractionOrders</a>. If we assume our contraction-order finding program has found the optimal treewidth, which is very likely to be true, the space complexity is the same as the treewidth of the problem graph. Slicing technique has been used for graphs with space complexity greater than <span>$2^{27}$</span> (above the yellow dashed line) to fit the computation into a 16GB memory. One can see that all the computation times in panels (b), (c), and (d) have a strong correlation with the predicted time and space complexity. While in panel (d), the computation time of configuration enumeration also strongly correlates with other factors such as the configuration space size. Among these benchmarks, computational tasks with data types real numbers, complex numbers, or <a href="../ref/#TropicalNumbers.Tropical"><code>Tropical</code></a> numbers (CPU only) can utilize fast basic linear algebra subprograms (BLAS) functions. These tasks usually compute much faster than ones with other element types in the same category. Immutable data types with no reference to other values can be compiled to GPU devices that run much faster than CPUs in all cases when the problem scale is big enough. These data types do not include those defined in <a href="https://juliamath.github.io/Polynomials.jl/stable/polynomials/polynomial/#Polynomial-2"><code>Polynomial</code></a>, <a href="../ref/#GenericTensorNetworks.ConfigEnumerator"><code>ConfigEnumerator</code></a>, <a href="../ref/#GenericTensorNetworks.ExtendedTropical"><code>ExtendedTropical</code></a> and <a href="../ref/#GenericTensorNetworks.SumProductTree"><code>SumProductTree</code></a> or a data type containing them as a part. In panel (c), one can see the Fourier transformation-based method is the fastest in computing the independence polynomial, but it may suffer from round-off errors. The finite field (GF(p)) approach is the only method that does not have round-off errors and can be run on a GPU. In panel (d), one can see the technique to bound the enumeration space (see paper) improves the performance for more than one order of magnitude in enumerating the MISs. The bounding technique can also reduce the memory usage significantly, without which the largest computable graph size is only <span>$\sim150$</span> on a device with 32GB main memory.</p><p>We show the benchmark of computing the maximal independent set properties on 3-regular graphs in the following plot, including a comparison to the Bron-Kerbosch algorithm from Julia package <a href="https://github.com/JuliaGraphs/Graphs.jl">Graphs</a></p><p><img src="../assets/fig2.png" alt="benchmark-maximal-independent-set"/></p><p>In this plot, benchmarks of computing different solution space properties of the maximal independent sets (ISs) problem on random three regular graphs at different sizes.</p><ul><li>(a) time and space complexity of tensor network contraction.</li><li>(b) The wall clock time for counting and enumeration of maximal ISs.</li></ul><p>Panel (a) shows the space and time complexities of tensor contraction, which are typically larger than those for the independent set problem. In panel (b), one can see counting maximal independent sets are much more efficient than enumerating them, while our generic tensor network approach runs slightly faster than the Bron-Kerbosch approach in enumerating all maximal independent sets.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../generated/open/">« Open and fixed degrees of freedom</a><a class="docs-footer-nextpage" href="../ref/">References »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.19 on <span class="colophon-date" title="Tuesday 28 June 2022 06:32">Tuesday 28 June 2022</span>. Using Julia version 1.7.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
